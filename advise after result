Je vais aller droit au but : on voit tr√®s bien qui fait mal et o√π √ßa tape.

‚∏ª

1. Ce que raconte la photo globale
	‚Ä¢	Instance SQL 2017 Enterprise sur un serveur avec 230 Go de RAM, mais SQL est limit√© √† 25 Go (max server memory = 25000).
	‚Ä¢	SQL utilise √† peu pr√®s sa limite (25 Go), et l‚ÄôOS a encore ~34 Go libres ‚Üí tu pourrais largement donner plus de RAM √† SQL si l‚Äôinstance est d√©di√©e.

Wait stats

Top waits int√©ressants (cumul√©s depuis longtemps, mais √ßa donne la couleur) :
	‚Ä¢	PAGEIOLATCH_SH = 10,14 %
	‚Ä¢	PAGEIOLATCH_EX = 4,85 %
	‚Ä¢	WRITELOG = 1,31 %
	‚Ä¢	Quelques ASYNC_IO_COMPLETION mais tr√®s minoritaire.

Le reste (WAITFOR, QDS_*, LOGMGR_QUEUE, CHECKPOINT_QUEUE‚Ä¶) ce sont surtout des waits ‚Äúde fond‚Äù/idle.

üëâ Donc clairement :
probl√©matique principale = latence lecture (PAGEIOLATCH_SH/EX)
un peu d‚ÄôI/O √©criture (WRITELOG), mais ce n‚Äôest pas le #1.

‚∏ª

2. O√π √ßa tape sur les disques (dm_io_virtual_file_stats)

2.1. Lecture

Les pires en lecture :
	‚Ä¢	Les fichiers de DB_TDR (sur K:\APP\MSSQL\), avec :
	‚Ä¢	avg_read_ms ‚âà 14 ms et beaucoup d‚ÄôI/O (plusieurs milliards de lectures).
	‚Ä¢	Les grosses bases m√©tier sur K: (DB_EVODATA, DB_PMU, DB_EVOBUS) :
	‚Ä¢	avg_read_ms entre 9 et 13 ms
	‚Ä¢	Certaines bases historiques (DB_PMU_HISTO sur M:) ont ~17 ms.

Ce ne sont pas des pics ridicules, mais 14 ms de moyenne sur des volumes aussi massifs, plus PAGEIOLATCH √©lev√©, √ßa fait un syst√®me clairement I/O bound en lecture.

2.2. √âcriture

Tri√© par avg_write_ms, on voit :
	‚Ä¢	DB_SLIB (sur K:) :
	‚Ä¢	avg_write_ms entre 83 et 100 ms ü§ï
	‚Ä¢	avg_read_ms 4‚Äì6 ms ‚Üí lecture OK, mais √©criture catastrophique.
	‚Ä¢	Les grosses bases m√©tier (TDR, PMU, EVODATA‚Ä¶) :
	‚Ä¢	avg_write_ms plut√¥t dans les 12‚Äì15 ms ‚Üí pas super, mais acceptable pour un LUN partag√© charg√©.

üëâ Conclusion disque :
	‚Ä¢	LUN K: est le gros point chaud (TDR, SLIB, PMU, EVODATA, EVOBUS, etc.).
	‚Ä¢	DB_SLIB est un gros consommateur en √©criture avec des latences monstrueuses.
	‚Ä¢	DB_TDR et PMU/EVODATA/EVOBUS sont lourdes en lecture (et un peu en √©criture) avec des latences moyennes mais sur des volumes gigantesques ‚Üí √ßa explique PAGEIOLATCH.

‚∏ª

3. Qui mange la RAM (buffer cache)

R√©partition du buffer :
	‚Ä¢	DB_TDR : ~13 Go (66 % du cache)
	‚Ä¢	DB_PMU : ~3,9 Go (19 %)
	‚Ä¢	DB_SLIB : ~1,8 Go (9 %)
	‚Ä¢	Le reste se partage les miettes.

Et ton max server memory = 25 Go ‚Üí le buffer pool fait ~20‚Äì21 Go.

üëâ En gros, 3 bases (TDR, PMU, SLIB) se partagent presque toute la RAM SQL, alors qu‚Äôelles repr√©sentent des volumes √©normes (plusieurs To).
R√©sultat :
	‚Ä¢	Le cache est trop petit par rapport aux volumes acc√©d√©s.
	‚Ä¢	SQL doit √©vacuer des pages souvent ‚Üí PAGEIOLATCH_SH en hausse, donc beaucoup de lectures disque.

Avec 230 Go de RAM sur la machine, tu pourrais facilement doubler/tripler la m√©moire SQL si l‚Äôinstance est seule.

‚∏ª

4. Top requ√™tes I/O : qui flingue les disques

4.1. Top physical reads

Les grosses lectures physiques sont surtout sur :
	‚Ä¢	DB_TDR (largement en t√™te)
Exemple : une query avec
total_physical_reads = 496 636 920 pour 131 ex√©cutions
total_logical_reads ~ 528 M
total_duration_ms ~ 4 103 017 ms (‚âà 68 min cumul√©es)

Plusieurs autres queries TDR entre 20‚Äì80 M physical reads.
	‚Ä¢	DB_PMU et DB_EVODATA / EVOBUS ont √©galement des queries tr√®s lourdes en I/O, mais TDR domine.

Donc DB_TDR est ton principal g√©n√©rateur d‚ÄôI/O disque.

4.2. Top logical reads

C√¥t√© logical reads :
	‚Ä¢	DB_SLIB explose tout :
	‚Ä¢	queries avec ~7,15 milliards de logical reads (!)
	‚Ä¢	tr√®s peu de physical ‚Üí √ßa se passe beaucoup en m√©moire, mais :
	‚Ä¢	√ßa consomme beaucoup de CPU
	‚Ä¢	√ßa g√©n√®re beaucoup d‚Äô√©critures (et on a vu avg_write_ms ~ 90‚Äì100 ms)

Le paquet NULL en DBName c√¥t√© logical reads vient souvent de requ√™tes syst√®me / internal ou de plans o√π la dbid n‚Äôest pas renseign√©e, moins prioritaires √† ce stade.

üëâ En r√©sum√© :
	‚Ä¢	TDR = AMOK sur les lectures physiques.
	‚Ä¢	SLIB = AMOK sur les lectures logiques + √©critures tr√®s lentes.

‚∏ª

5. Requ√™tes actives (dm_exec_requests)

Quelques points marquants :
	‚Ä¢	session_id 89 : DbccFilesCompact sur tempdb ‚Üí
LCK_M_BU sur [ENCRYPTION_SCAN]
‚Üí SHRINKFILE tempdb avec TDE/chiffrement ‚Üí tr√®s mauvais pour les perfs.
‚ûú √Ä stopper / √† ne plus planifier en prod si possible.
	‚Ä¢	session_id 87 (DB_TDR) : gros SELECT INTO #ordrenego
	‚Ä¢	depuis TBLORDERS avec Time_System >= @DATE_DEBUT / < @DATE_FIN, OwnerDesk IN (...), Type in (...)
	‚Ä¢	NOLOCK (donc gros scans possibles)
	‚Ä¢	DENSE_RANK() ‚Üí fen√™tre analytique ‚Üí peut forcer des gros sorts.
	‚Ä¢	session_id 110 (DB_TDR) : SELECT TOP (@topLignes) ord.table_Id INTO #EDA_TBLORDERSIds
	‚Ä¢	FROM TBLORDERS o√π Date_System >= DATEADD(day, -5, getdate())
	‚Ä¢	LEFT JOIN TDR_EPRO_EntityProcessing
	‚Ä¢	WHERE epro.Id is null
‚Üí typique du batch d‚Äôexport / rattrapage : gros scan sur TBLORDERS.
	‚Ä¢	session_id 151 (DB_TDR) : SELECT COUNT(1) FROM TDR_export_messageout WHERE processedOn IS NOT NULL AND processedon BETWEEN @FirstDate AND @LastDate
	‚Ä¢	sur TDR ‚Üí si non index√© sur processedOn, c‚Äôest un gros scan.
	‚Ä¢	session_id 73 (DB_SLIB) : Insert Work_SLB_GetExternalExecution ... FROM SLB_EXE_Execution LEFT JOIN SLB_SUR_SUIVIREFERENCE
‚Üí beaucoup d‚Äô√©critures SLIB + JOINS ‚Üí c‚Äôest coh√©rent avec les latences d‚Äô√©criture.

üëâ On voit bien :
	‚Ä¢	TDR : grosses requ√™tes d‚Äôexport / agr√©gats / SELECT INTO, tr√®s consommatrices en I/O.
	‚Ä¢	SLIB : batch d‚Äôinsertion avec gros joins, sur une base dont les writes sont d√©j√† tr√®s lents.

‚∏ª

6. Tempdb
	‚Ä¢	8 fichiers data de 9,6 Go sur T:\ ‚Üí OK en nombre.
	‚Ä¢	unallocated_MB ~ 76 Go, user_objects 102 Mo, version_store 147 Mo ‚Üí tempdb loin d‚Äô√™tre pleine.
	‚Ä¢	Quelques waits PAGEIOLATCH_* sur tempdb, mais rien d‚Äôaffolant.
	‚Ä¢	Le principal probl√®me tempdb, c‚Äôest le SHRINK en cours (session 89).

‚∏ª

7. Analyse synth√©tique

7.1. Causes probables du pic d‚ÄôI/O
	1.	M√©moire SQL insuffisante par rapport au volume de donn√©es actives
	‚Ä¢	SQL n‚Äôa que 25 Go sur un host √† 230 Go.
	‚Ä¢	TDR + PMU + SLIB √† eux seuls consomment la quasi-totalit√© du cache.
	‚Ä¢	Beaucoup de relectures disques ‚Üí PAGEIOLATCH_SH.
	2.	Gros workloads I/O sur TDR et PMU / EVODATA / EVOBUS
	‚Ä¢	Queries d‚Äôexport/agr√©gats sur TBLORDERS, TDR_export_messageout, etc.
	‚Ä¢	Tables massives avec scans fr√©quents ‚Üí total_physical_reads tr√®s √©lev√©.
	3.	Base SLIB tr√®s √©criture-intensive avec latence disque √©norme
	‚Ä¢	avg_write_ms ‚âà 90‚Äì100 ms sur plusieurs fichiers SLIB.
	‚Ä¢	batches d‚Äôinsert (Work_SLB_GetExternalExecution‚Ä¶) qui empilent les writes.
	4.	LUN K: satur√© (toutes les bases lourdes sont dessus)
	‚Ä¢	TDR, SLIB, PMU, EVODATA, EVOBUS, etc.
	‚Ä¢	C‚Äôest ton gros chauffe-plat I/O.
	5.	Maintenance inadapt√©e : SHRINK tempdb
	‚Ä¢	DbccFilesCompact avec ENCRYPTION_SCAN ‚Üí √ßa bloque, √ßa g√©n√®re de l‚ÄôI/O inutile, √ßa fragmente, √ßa ne r√©sout rien.

‚∏ª

8. Plan d‚Äôaction concret

8.1. Actions rapides (√† tr√®s fort ROI)
	1.	Augmenter max server memory pour SQL Server
Si cette instance est quasiment seule sur le serveur, je viserais :
	‚Ä¢	passer de 25 Go √† 80‚Äì120 Go comme point de d√©part.
	‚Ä¢	garder 30‚Äì50 Go pour l‚ÄôOS/antivirus/agents √©ventuellement.


EXEC sp_configure 'show advanced options', 1;
RECONFIGURE;
EXEC sp_configure 'max server memory (MB)', 100000; -- exemple 100 Go
RECONFIGURE;



‚ûú Objectif : r√©duire drastiquement les lectures disque sur TDR/PMU/SLIB ‚Üí baisse de PAGEIOLATCH_SH.

	2.	Arr√™ter et proscrire les SHRINK sur tempdb
	‚Ä¢	Stopper la session 89 (KILL 89) si possible en p√©riode de calme.
	‚Ä¢	Supprimer toute t√¢che de maintenance qui fait DBCC SHRINKFILE/SHRINKDATABASE sur tempdb ou les bases actives.
	3.	Index sur les queries TDR les plus violentes
a) TDR_export_messageout(processedOn) :


CREATE NONCLUSTERED INDEX IX_TDR_export_messageout_ProcessedOn
ON TDR_export_messageout(processedOn)
WHERE processedOn IS NOT NULL;

CREATE NONCLUSTERED INDEX IX_TDR_export_messageout_ProcessedOn
ON TDR_export_messageout(processedOn)
WHERE processedOn IS NOT NULL;

(Filtr√©, on est en Enterprise ‚Üí parfait pour le COUNT avec date range.)
b) TBLORDERS (Time_System, OwnerDesk, Type) :



CREATE NONCLUSTERED INDEX IX_TBLORDERS_TimeSystem_Desk_Type
ON TBLORDERS(Time_System, OwnerDesk, Type)
INCLUDE (OrderId, RefInstrument, Quantity_Size, Side, Price_Limit, ClientId, table_Id, Price_avg);



c) TBLORDERS (Date_System, table_Id) pour la query Date_System >= DATEADD(day,-5, getdate()) :


CREATE NONCLUSTERED INDEX IX_TBLORDERS_DateSystem_TableId
ON TBLORDERS(Date_System, table_Id);


d) TDR_EPRO_EntityProcessing pour le LEFT JOIN Entity = 'EDA_TBLORDERS' AND EntityId = ord.table_Id :

CREATE NONCLUSTERED INDEX IX_TDR_EPRO_Entity_EntityId
ON TDR_EPRO_EntityProcessing(Entity, EntityId)
INCLUDE (Id);


‚ûú Objectif : √©viter les scans massifs TBLORDERS / TDR_export_messageout.

	4.	V√©rifier / r√©duire la fr√©quence des batchs gourmands TDR
	‚Ä¢	Revoir la fr√©quence de lancement des gros SELECT INTO (#ordrenego, #EDA_TBLORDERSIds).
	‚Ä¢	Id√©alement les s√©quencer ou les d√©placer en heures creuses si ce n‚Äôest pas d√©j√† le cas.

‚∏ª

8.2. Actions infra / stockage
	1.	Discuter du LUN K:\ avec l‚Äô√©quipe infra
Points √† v√©rifier :
	‚Ä¢	IOPS / latence vue c√¥t√© SAN/ESXi sur K: (lectures & √©critures).
	‚Ä¢	d‚Äôautres VM tapent sur le m√™me datastore ?
	‚Ä¢	QoS / priorisation possible pour cette instance ?
Objectif : faire descendre les latences :
	‚Ä¢	en lecture id√©alement < 5‚Äì8 ms
	‚Ä¢	en √©criture < 10 ms.
	2.	Isoler SLIB sur un volume plus adapt√©
Vu les avg_write_ms de SLIB, je recommanderais :
	‚Ä¢	soit d√©placer SLIB (ou au moins ses fichiers les plus chauds) sur un LUN d√©di√© plus performant,
	‚Ä¢	soit all√©ger ses batchs (voir plus bas).

‚∏ª

8.3. Actions sur SLIB (batchs ETL tr√®s lourds)
	1.	Analyser les plans des queries SLIB top logical reads
	‚Ä¢	Notamment les SELECT/INSERT que tu m‚Äôas montr√©s (Work_SLB_GetExternalExecution, etc.).
	‚Ä¢	Chercher :
	‚Ä¢	scans sur SLB_EXE_Execution,
	‚Ä¢	join vers SLB_SUR_SUIVIREFERENCE mal index√©.
	2.	Ajouter des index cibl√©s
Par exemple, pour :


FROM SLB_EXE_Execution EXE
LEFT JOIN SLB_SUR_SUIVIREFERENCE SUR
      ON SUR.SUR_ENTITE = 'EXECUTION'
     AND SUR_REFERENCE = TradeId
     AND SUR.SUR_DHCREATION > convert(date,dateadd(day,-5,getdate()),112)
WHERE SUR_ID IS NULL
  AND EXE.InstrumentId IS NOT NULL
  AND EXE.CreatedOn > convert(date,dateadd(day,-5,getdate()),112)


On peut imaginer :

	CREATE NONCLUSTERED INDEX IX_SLB_EXE_Execution_CreatedOn_InstrumentId
ON SLB_EXE_Execution(CreatedOn, InstrumentId)
INCLUDE (TradeId, customDatas);

CREATE NONCLUSTERED INDEX IX_SLB_SUR_SUIVIREFERENCE_Entite_Reference_DHC
ON SLB_SUR_SUIVIREFERENCE(SUR_ENTITE, SUR_REFERENCE, SUR_DHCREATION)
INCLUDE (SUR_ID);

√áa d√©pend de la r√©alit√©, mais l‚Äôid√©e est l√†.

	3.	Limiter le volume par batch
	‚Ä¢	Si possible, travailler par fen√™trage temporel plus fin (par jour, par heure) plut√¥t que de gros rattrapages de plusieurs jours/semaines.
	‚Ä¢	√áa r√©duit le pic I/O et la taille des temp tables.

‚∏ª

9. Pour la suite

Si tu veux, on peut faire encore plus cibl√© :
	1.	Tu me colles le texte complet de 2‚Äì3 des pires queries :
	‚Ä¢	1‚Äì2 sur DB_TDR (celles √† 400‚Äì500M physical reads),
	‚Ä¢	1 sur DB_SLIB (top logical reads ou celle de Work_SLB_GetExternalExecution),
	2.	Je te propose :
	‚Ä¢	index pr√©cis (cl√© + INCLUDE),
	‚Ä¢	√©ventuellement une r√©√©criture de la requ√™te pour limiter les scans (CTE, fen√™trage, pr√©-filtrage, etc.).

Mais d√©j√†, m√™me sans √ßa, tes gros leviers imm√©diats sont :
	‚Ä¢	Augmenter la m√©moire SQL (tr√®s important ici).
	‚Ä¢	Stopper les SHRINK.
	‚Ä¢	Indexer / optimiser les gros batchs TDR + SLIB.
	‚Ä¢	Discuter du LUN K: avec l‚Äôinfra.